{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iG9Az0z2t7ye"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # Can slow down but ensures determinism\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mobilenet import MobileNet\n",
    "from data import get_train_valid_loader, get_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hlgcY9H185AF"
   },
   "outputs": [],
   "source": [
    "def train_func(model, optimizer, criterion, train_loader, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def eval(model, criterion, valid_loader, device):\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    valid_loss = valid_loss / len(valid_loader)\n",
    "    valid_accuracy = 100 * correct / total\n",
    "\n",
    "    return valid_loss, valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_dir = './data'\n",
    "train_loader, valid_loader = get_train_valid_loader(data_dir=data_dir,batch_size=batch_size,augment=True,random_seed=42)\n",
    "test_loader = get_test_loader(data_dir=data_dir, batch_size=batch_size)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "momentum = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2: Training with cosine annealing learning rate\n",
      "Epoch [1/300], Train Loss: 4.1285, Train Acc: 6.48%, Valid Loss: 3.7877, Valid Acc: 10.27%, Learning Rate: 0.049999\n",
      "Epoch [11/300], Train Loss: 2.1332, Train Acc: 41.97%, Valid Loss: 2.3250, Valid Acc: 39.33%, Learning Rate: 0.049834\n",
      "Epoch [21/300], Train Loss: 1.3774, Train Acc: 59.57%, Valid Loss: 1.9743, Valid Acc: 49.14%, Learning Rate: 0.049398\n",
      "Epoch [31/300], Train Loss: 0.8732, Train Acc: 72.80%, Valid Loss: 2.0867, Valid Acc: 50.64%, Learning Rate: 0.048694\n",
      "Epoch [41/300], Train Loss: 0.4658, Train Acc: 84.71%, Valid Loss: 2.3229, Valid Acc: 52.64%, Learning Rate: 0.047731\n",
      "Epoch [51/300], Train Loss: 0.2514, Train Acc: 91.73%, Valid Loss: 2.5893, Valid Acc: 53.02%, Learning Rate: 0.046519\n",
      "Epoch [61/300], Train Loss: 0.1417, Train Acc: 95.42%, Valid Loss: 2.8016, Valid Acc: 54.30%, Learning Rate: 0.045070\n",
      "Epoch [71/300], Train Loss: 0.0842, Train Acc: 97.37%, Valid Loss: 2.9750, Valid Acc: 53.96%, Learning Rate: 0.043402\n",
      "Epoch [81/300], Train Loss: 0.0599, Train Acc: 98.08%, Valid Loss: 3.0756, Valid Acc: 54.76%, Learning Rate: 0.041533\n",
      "Epoch [91/300], Train Loss: 0.0360, Train Acc: 98.92%, Valid Loss: 3.1203, Valid Acc: 54.80%, Learning Rate: 0.039482\n",
      "Epoch [101/300], Train Loss: 0.0247, Train Acc: 99.23%, Valid Loss: 3.1635, Valid Acc: 55.33%, Learning Rate: 0.037273\n",
      "Epoch [111/300], Train Loss: 0.0172, Train Acc: 99.48%, Valid Loss: 3.2432, Valid Acc: 55.29%, Learning Rate: 0.034929\n",
      "Epoch [121/300], Train Loss: 0.0104, Train Acc: 99.72%, Valid Loss: 3.2612, Valid Acc: 55.46%, Learning Rate: 0.032476\n",
      "Epoch [131/300], Train Loss: 0.0077, Train Acc: 99.79%, Valid Loss: 3.3086, Valid Acc: 55.59%, Learning Rate: 0.029941\n",
      "Epoch [141/300], Train Loss: 0.0060, Train Acc: 99.84%, Valid Loss: 3.2933, Valid Acc: 55.93%, Learning Rate: 0.027353\n",
      "Epoch [151/300], Train Loss: 0.0044, Train Acc: 99.89%, Valid Loss: 3.2957, Valid Acc: 56.33%, Learning Rate: 0.024738\n",
      "Epoch [161/300], Train Loss: 0.0035, Train Acc: 99.92%, Valid Loss: 3.3018, Valid Acc: 56.53%, Learning Rate: 0.022127\n",
      "Epoch [171/300], Train Loss: 0.0034, Train Acc: 99.90%, Valid Loss: 3.3318, Valid Acc: 56.79%, Learning Rate: 0.019546\n",
      "Epoch [181/300], Train Loss: 0.0023, Train Acc: 99.94%, Valid Loss: 3.3430, Valid Acc: 56.50%, Learning Rate: 0.017026\n",
      "Epoch [191/300], Train Loss: 0.0023, Train Acc: 99.95%, Valid Loss: 3.3389, Valid Acc: 56.64%, Learning Rate: 0.014593\n",
      "Epoch [201/300], Train Loss: 0.0017, Train Acc: 99.96%, Valid Loss: 3.3423, Valid Acc: 56.75%, Learning Rate: 0.012274\n",
      "Epoch [211/300], Train Loss: 0.0017, Train Acc: 99.94%, Valid Loss: 3.3514, Valid Acc: 56.79%, Learning Rate: 0.010094\n",
      "Epoch [221/300], Train Loss: 0.0016, Train Acc: 99.95%, Valid Loss: 3.3499, Valid Acc: 56.76%, Learning Rate: 0.008078\n",
      "Epoch [231/300], Train Loss: 0.0014, Train Acc: 99.97%, Valid Loss: 3.3555, Valid Acc: 56.46%, Learning Rate: 0.006247\n",
      "Epoch [241/300], Train Loss: 0.0013, Train Acc: 99.96%, Valid Loss: 3.3547, Valid Acc: 56.74%, Learning Rate: 0.004622\n",
      "Epoch [251/300], Train Loss: 0.0015, Train Acc: 99.95%, Valid Loss: 3.3401, Valid Acc: 56.79%, Learning Rate: 0.003220\n",
      "Epoch [261/300], Train Loss: 0.0013, Train Acc: 99.96%, Valid Loss: 3.3529, Valid Acc: 56.97%, Learning Rate: 0.002056\n",
      "Epoch [271/300], Train Loss: 0.0013, Train Acc: 99.96%, Valid Loss: 3.3450, Valid Acc: 56.89%, Learning Rate: 0.001144\n",
      "Epoch [281/300], Train Loss: 0.0012, Train Acc: 99.97%, Valid Loss: 3.3589, Valid Acc: 56.96%, Learning Rate: 0.000493\n",
      "Epoch [291/300], Train Loss: 0.0013, Train Acc: 99.97%, Valid Loss: 3.3320, Valid Acc: 56.92%, Learning Rate: 0.000111\n",
      "Epoch [300/300], Train Loss: 0.0012, Train Acc: 99.97%, Valid Loss: 3.3418, Valid Acc: 56.75%, Learning Rate: 0.000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m train_losses, valid_losses, train_accuracies, valid_accuracies \u001b[38;5;241m=\u001b[39m train_cosine_annealing(\n\u001b[1;32m     50\u001b[0m     model, learning_rate, criterion, train_loader, valid_loader, device, num_epochs)\n\u001b[1;32m     52\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     53\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_losses)), train_losses)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for the new experiments\n",
    "num_epochs = 300\n",
    "learning_rate = 0.05 # best learning rate from the previous experiment \n",
    "\n",
    "# Function to train with cosine annealing learning rate\n",
    "def train_cosine_annealing(model, initial_lr, criterion, train_loader, valid_loader, device, num_epochs):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=initial_lr, momentum=momentum)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    learning_rates = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_func(model, optimizer, criterion, train_loader, device, epoch)\n",
    "        valid_loss, valid_accuracy = eval(model, criterion, valid_loader, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Get the current learning rate\n",
    "        current_lr = scheduler.get_last_lr()[0]  # Extract current learning rate\n",
    "        learning_rates.append(current_lr)\n",
    "        if epoch % 10 == 0 or epoch == num_epochs-1:\n",
    "            \n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Train Acc: {train_accuracy:.2f}%, \"\n",
    "                  f\"Valid Loss: {valid_loss:.4f}, \"\n",
    "                  f\"Valid Acc: {valid_accuracy:.2f}%, \"\n",
    "                  f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    return train_losses, valid_losses, train_accuracies, valid_accuracies, learning_rates\n",
    "    \n",
    "# Experiment 2: Train for 300 epochs with cosine annealing learning rate\n",
    "print(\"Experiment 2: Training with cosine annealing learning rate\")\n",
    "\n",
    "model = MobileNet(num_classes=100, sigmoid_block_ind = []).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "train_losses, valid_losses, train_accuracies, valid_accuracies = train_cosine_annealing(\n",
    "    model, learning_rate, criterion, train_loader, valid_loader, device, num_epochs)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(len(train_losses)), train_losses)\n",
    "plt.plot(range(len(valid_losses)), valid_losses)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"MobileNet with Consine Annealing LR\")\n",
    "plt.legend(['train', 'valid'])\n",
    "plt.savefig('images/cosine_annealing_loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(len(train_accuracies)), train_accuracies)\n",
    "plt.plot(range(len(valid_accuracies)), valid_accuracies)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MobileNet with Consine Annealing LR\")\n",
    "plt.legend(['train', 'valid'])\n",
    "plt.savefig('images/cosine_annealing_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "learning_curves = {\"train_losses\": train_losses,\n",
    "                    \"valid_losses\": valid_losses,\n",
    "                    \"train_accuracies\": train_accuracies,\n",
    "                    \"valid_accuracies\": valid_accuracies,\n",
    "                   'learning_rates': learning_rates\n",
    "                    }\n",
    "\n",
    "with open(f'learning_curves/cosine_annealing.json', 'w') as fp:\n",
    "    json.dump(learning_curves, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author identity unknown\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'root@8ac860666ac8.(none)')\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"Auto-commit after Consine Annealing experiment\"\n",
    "!git push origin main  # Change \"main\" to your branch name"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
